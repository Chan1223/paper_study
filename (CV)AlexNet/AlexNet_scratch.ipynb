{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 호출\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 토치비전 transform 및 데이터셋 가져오기\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# 데이터 로더 가져오기\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# 최적화 알고리즘 가져오기 \n",
    "from torch.optim import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 transform 적용\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((227,227)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기(fashion MNIST 사용)\n",
    "\n",
    "path = '/home/helpme/data/FashionMNIST'\n",
    "\n",
    "train_data = FashionMNIST(\n",
    "    root = path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=data_transforms\n",
    ")\n",
    "\n",
    "test_data = FashionMNIST(\n",
    "    root = path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=data_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 4\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /home/helpme/data/FashionMNIST\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(227, 227), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수 : 60000\n",
      "test data 개수 : 10000\n",
      "x shape (N, C, H, W): torch.Size([128, 1, 227, 227])\n",
      "y shape : (torch.Size([128]), torch.int64)\n"
     ]
    }
   ],
   "source": [
    "print(f'train data 개수 : {len(train_dataloader.dataset)}')\n",
    "print(f'test data 개수 : {len(test_dataloader.dataset)}')\n",
    "\n",
    "for x, y in test_dataloader:\n",
    "    print(f'x shape (N, C, H, W): {x.shape}')\n",
    "    print(f'y shape : {y.shape, y.dtype}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 만들기\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            \n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=256*6*6, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)            \n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)        \n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(in_features=4096, out_features=10)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc3): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [16, 96, 55, 55]          11,712\n",
      "              ReLU-2           [16, 96, 55, 55]               0\n",
      " LocalResponseNorm-3           [16, 96, 55, 55]               0\n",
      "         MaxPool2d-4           [16, 96, 27, 27]               0\n",
      "            Conv2d-5          [16, 256, 27, 27]         614,656\n",
      "              ReLU-6          [16, 256, 27, 27]               0\n",
      " LocalResponseNorm-7          [16, 256, 27, 27]               0\n",
      "         MaxPool2d-8          [16, 256, 13, 13]               0\n",
      "            Conv2d-9          [16, 384, 13, 13]         885,120\n",
      "             ReLU-10          [16, 384, 13, 13]               0\n",
      "           Conv2d-11          [16, 384, 13, 13]       1,327,488\n",
      "             ReLU-12          [16, 384, 13, 13]               0\n",
      "           Conv2d-13          [16, 256, 13, 13]         884,992\n",
      "             ReLU-14          [16, 256, 13, 13]               0\n",
      "        MaxPool2d-15            [16, 256, 6, 6]               0\n",
      "           Linear-16                 [16, 4096]      37,752,832\n",
      "             ReLU-17                 [16, 4096]               0\n",
      "          Dropout-18                 [16, 4096]               0\n",
      "           Linear-19                 [16, 4096]      16,781,312\n",
      "             ReLU-20                 [16, 4096]               0\n",
      "          Dropout-21                 [16, 4096]               0\n",
      "           Linear-22                   [16, 10]          40,970\n",
      "================================================================\n",
      "Total params: 58,299,082\n",
      "Trainable params: 58,299,082\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.15\n",
      "Forward/backward pass size (MB): 234.89\n",
      "Params size (MB): 222.39\n",
      "Estimated Total Size (MB): 460.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (1,227,227), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0 [25472/60000 (42%)]\tLoss: 0.468370\n",
      "Train Epoch:0 [51072/60000 (85%)]\tLoss: 0.367541\n",
      "Train Epoch:1 [25472/60000 (42%)]\tLoss: 0.222629\n",
      "Train Epoch:1 [51072/60000 (85%)]\tLoss: 0.296512\n",
      "Train Epoch:2 [25472/60000 (42%)]\tLoss: 0.279272\n",
      "Train Epoch:2 [51072/60000 (85%)]\tLoss: 0.339498\n",
      "Train Epoch:3 [25472/60000 (42%)]\tLoss: 0.438222\n",
      "Train Epoch:3 [51072/60000 (85%)]\tLoss: 0.192673\n",
      "Train Epoch:4 [25472/60000 (42%)]\tLoss: 0.276463\n",
      "Train Epoch:4 [51072/60000 (85%)]\tLoss: 0.341105\n",
      "Train Epoch:5 [25472/60000 (42%)]\tLoss: 0.188108\n",
      "Train Epoch:5 [51072/60000 (85%)]\tLoss: 0.304692\n",
      "Train Epoch:6 [25472/60000 (42%)]\tLoss: 0.119967\n",
      "Train Epoch:6 [51072/60000 (85%)]\tLoss: 0.140727\n",
      "Train Epoch:7 [25472/60000 (42%)]\tLoss: 0.175114\n",
      "Train Epoch:7 [51072/60000 (85%)]\tLoss: 0.161838\n",
      "Train Epoch:8 [25472/60000 (42%)]\tLoss: 0.115868\n",
      "Train Epoch:8 [51072/60000 (85%)]\tLoss: 0.194201\n",
      "Train Epoch:9 [25472/60000 (42%)]\tLoss: 0.194191\n",
      "Train Epoch:9 [51072/60000 (85%)]\tLoss: 0.125336\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \t\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \t\t\n",
    "        if (i+1) % 200 == 0:\n",
    "            # print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        \t# \t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, i * len(images), len(train_dataloader.dataset),\n",
    "                100. * i / len(train_dataloader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 90.98 %\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
